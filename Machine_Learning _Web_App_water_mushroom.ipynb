{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY2y84twsO7U",
        "outputId": "2dbe3d25-a878-48aa-fa1c-49494ca4d3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Collecting packaging<24,>=16.8 (from streamlit)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, packaging, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 packaging-23.2 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.32.2 watchdog-4.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#StackingClassifier için base model ve meta model tanımlamaları\n",
        "\n",
        "#  StackingClassifier, birden fazla temel modelin (base model) tahminlerini bir araya getirerek daha iyi bir tahmin yapmaya çalışan bir sınıflandırıcıdır.\n",
        "# Bu model, meta-model olarak adlandırılan bir modeli kullanarak temel modellerin tahminlerini birleştirir.\n",
        "\n",
        "#  Base Models (Temel Modeller): Bu modeller, farklı algoritmaları veya farklı hiperparametre ayarlarını kullanarak oluşturulan çeşitli\n",
        "# sınıflandırıcı veya regresyon modelleridir. Örneğin, RandomForestClassifier, LogisticRegression, SVC gibi farklı algoritmaları veya bu algoritmaların farklı\n",
        "# hiperparametre kombinasyonlarını temsil edebilirler.\n",
        "\n",
        "#  Meta Model: Bu model, temel modellerin tahminlerini bir araya getirerek son tahmini oluşturur.\n",
        "# Tipik olarak, meta-model daha basit bir modeldir ve temel modellerin çıktılarını birleştirmek veya ağırlamak için kullanılır.\n",
        "# Örneğin, meta-model olarak genellikle Logistic Regression veya RandomForest gibi daha basit bir model kullanılır.\n",
        "\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "    ('svm', SVC())\n",
        "]\n",
        "\n",
        "meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "#İnternet sitesinin sidebarına radio butonlar ekler. Sayfalar arası gezmek için kullanılmıştır.\n",
        "rad= st.sidebar.radio(\"Menu\",[\"Home\",\"Mantar Yenilebilirliği\",\"Su İçilebilirliği\"])\n",
        "\n",
        "#Anasayfa\n",
        "if rad==\"Home\":\n",
        "  st.title(\"201505032 Kerim Berkay Buçan\")\n",
        "  st.text(\"Aşağıdaki datasetler üzerine karar destek sistemi oluşturulacaktır\")\n",
        "  st.text(\"1. Mantarın Yenilebilirliğinin Tespiti\")\n",
        "  st.text(\"2. Suyun İçilebilirliğinin Tespiti \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12B2J-6-tRIz",
        "outputId": "89349a7f-87b8-4933-9277-beb97a6186da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile -a app.py\n",
        "#Mantar verilerinin okunması ve verilerin oluşturulması\n",
        "#Mantar verileri string ifade olarak verildiği için OneHotEncoder ile binary sayılara çevrilmiştir.\n",
        "\n",
        "data_mushroom=pd.read_csv(\"/content/mushrooms.csv\")\n",
        "\n",
        "\n",
        "# Bu sütunlar, mantarların özelliklerini tanımlayan özniteliklerdir.\n",
        "categorical_columns_mushroom = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
        "                       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
        "                       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
        "                       'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring',\n",
        "                       'veil-type', 'veil-color', 'ring-number', 'ring-type',\n",
        "                       'spore-print-color', 'population', 'habitat']\n",
        "\n",
        "# OneHotEncoder sınıfından bir nesne oluşturur. Bu, kategorik sütunları ikili (binary) vektörler haline getirerek\n",
        "#makine öğrenimi modellerine uygun hale getirmek için kullanılır. 'drop=\"first\"' parametresi, ilk kategoriyi düşürerek çoklu doğrusallığı önler.\n",
        "encoder_mushroom = OneHotEncoder(drop='first', sparse=False)\n",
        "\n",
        "#OneHotEncoder'ı kullanarak kategorik sütunları dönüştürür\n",
        "encoded_data_mushroom = encoder_mushroom.fit_transform(data_mushroom[categorical_columns_mushroom])\n",
        "#Encode edilmiş veriyi bir DataFrame'e dönüştürür.\n",
        "encoded_df_mushroom = pd.DataFrame(encoded_data_mushroom, columns=encoder_mushroom.get_feature_names_out(categorical_columns_mushroom))\n",
        "\n",
        "# Bağımsız değişkenleri (X) ve bağımlı değişkeni (y) belirler. X, encode edilmiş DataFrame'i temsil ederken,\n",
        "# y \"class\" sütununu temsil eder, yani mantarın zehirli mi yoksa yenilebilir mi olduğunu gösterir.\n",
        "x_mushroom = encoded_df_mushroom\n",
        "y_mushroom = data_mushroom['class']\n",
        "\n",
        "# Veri kümesini eğitim ve test setlerine ayırır.\n",
        "# random_state=42  parametresi, veri setini rastgele bölerken tekrarlanabilirliği sağlar.\n",
        "xmushroom_train, xmushroom_test, ymushroom_train, ymushroom_test = train_test_split(x_mushroom, y_mushroom, test_size=0.2, random_state=42)\n",
        "\n",
        "#Random Forest modelinin oluşturulup eğitilmesi\n",
        "mushRoomRf=RandomForestClassifier()\n",
        "mushRoomRf.fit(xmushroom_train,ymushroom_train)\n",
        "\n",
        "# #Adaboost modelinin oluşturulup eğitilmesi\n",
        "mushRoomAb=AdaBoostClassifier()\n",
        "mushRoomAb.fit(xmushroom_train,ymushroom_train)\n",
        "\n",
        "# #BaggingClassifier modelinin oluşturulup eğitilmesi\n",
        "mushRoomBg=BaggingClassifier()\n",
        "mushRoomBg.fit(xmushroom_train,ymushroom_train)\n",
        "\n",
        "# #StackingClassifier modelinin oluşturulup eğitilmesi\n",
        "mushRoomSg=StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
        "mushRoomSg.fit(xmushroom_train,ymushroom_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83CBsDhpusCS",
        "outputId": "75f8f356-9a03-4af1-dcb0-bef23b392898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile -a app.py\n",
        "#Mushroom Tahmin\n",
        "if rad==\"Mantar Yenilebilirliği\":\n",
        "  st.header(\"Mantar Yenilebilir Mi Yenilemez Mi\")\n",
        "  #Tahmin yapılması için kullanıcıdan selectboxlarla verilerin alınması\n",
        "  cap_shape = st.selectbox(\n",
        "    'Kapak Şekli? çan = B, konik = C, dışbükey = X, düz = F, topuzlu = K, batık = S',\n",
        "    ('b', 'c', 'x', 'f', 'k', 's'))\n",
        "  cap_surface = st.selectbox(\n",
        "    'Kapak Yüzeyi? lifli = F, oluklar = G, pullu = Y, pürüzsüz = s',\n",
        "    ('f', 'g', 'y', 's'))\n",
        "  cap_color = st.selectbox(\n",
        "    'Kapak Rengi? Kahverengi = N, Buff = B, Tarçın = C, Gri = G, Yeşil = R, Pembe = P, Mor = U, Kırmızı = E, Beyaz = W, Sarı = Y',\n",
        "    ('n', 'b', 'c', 'g', 'r', 'p', 'u', 'e', 'w', 'y'))\n",
        "  bruises = st.selectbox(\n",
        "    'Çürük? Evet = t, Hayır = f',\n",
        "    ('t', 'f'))\n",
        "  odor = st.selectbox(\n",
        "    'Koku? badem = A, Anason = L, Kreozot = C, Balık = Y, faul = F, küflü = M, Yok = N, Keskin = P, baharatlı = S',\n",
        "    ('a', 'l', 'c', 'y', 'f', 'm', 'n', 'p', 's'))\n",
        "  gill_attachment = st.selectbox(\n",
        "    'Solungaç eki? ekli = A, azalan = D, serbest = F, çentikli = n',\n",
        "    ('a', 'd', 'f', 'n'))\n",
        "  gill_spacing = st.selectbox(\n",
        "    'solungaç aralığı? yakın = c, kalabalık = w, uzak = d',\n",
        "    ('c', 'w', 'd'))\n",
        "  gill_size = st.selectbox(\n",
        "    'solungaç boyutu? geniş = b, dar = n',\n",
        "    ('b', 'n'))\n",
        "  gill_color= st.selectbox(\n",
        "    'Solungaç rengi: siyah = k, kahverengi = n, buff = b, çikolata = h, gri = g, yeşil = r, turuncu = o, pembe = p, mor = u, kırmızı = e, beyaz = w, sarı = y',\n",
        "    ('k', 'n','b','h','g','r','o''p','u','e','w','y'))\n",
        "  stalk_shape = st.selectbox(\n",
        "    'Sap şekli?  büyütme = E, sivriltme = t',\n",
        "    ('e', 't'))\n",
        "\n",
        "  stalk_root = st.selectbox(\n",
        "    'Sap kökü? soğanlı = b, kulüp = c, fincan = u, eşit = e, rizomorflar = z, köklü = r, eksik =?',\n",
        "    ('b', 'c', 'u', 'e', 'z', 'r','?'))\n",
        "\n",
        "\n",
        "  stalk_surface_above_ring = st.selectbox(\n",
        "    'Halkanın üstünde sap yüzeyi? lifli = F, pullu = y, ipeksi = k, pürüzsüz = s',\n",
        "    ('f', 'y', 'k', 's'))\n",
        "  stalk_surface_below_ring = st.selectbox(\n",
        "    'Halkanın altında sap yüzeyi? lifli = F, pullu = y, ipeksi = k, pürüzsüz = s',\n",
        "    ('f', 'y', 'k', 's'))\n",
        "\n",
        "\n",
        "  stalk_color_above_ring = st.selectbox(\n",
        "    'Halkanın Üstünde Sap Rengi? Kahverengi = N, Buff = B, Tarçın = C, Gri = G, Turuncu = O, Pembe = P, Kırmızı = E, Beyaz = W, Sarı = Y',\n",
        "    ('n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'))\n",
        "\n",
        "\n",
        "  stalk_color_below_ring = st.selectbox(\n",
        "    'Halkanın altındaki sap rengi? kahverengi = n, buff = b, tarçın = c, gri = g, turuncu = o, pembe = p, kırmızı = e, beyaz = w, sarı = y',\n",
        "    ('n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'))\n",
        "\n",
        "\n",
        "  veil_type = st.selectbox(\n",
        "    'peçe tipi? kısmi=p,evrensel=u',\n",
        "    ('p', 'u'))\n",
        "\n",
        "  veil_color = st.selectbox(\n",
        "    'peçe rengi: kahverengi = n, turuncu = o, beyaz = w, sarı = y',\n",
        "    ('n', 'o', 'w', 'y'))\n",
        "  ring_number = st.selectbox(\n",
        "    'Zil numarası: Yok = N, Bir = O, İki = T',\n",
        "    ('n', 'o', 't'))\n",
        "  ring_type = st.selectbox(\n",
        "    'Halka tipi: örümcek ağı = C, Evanescent = E, Parlama = F, Büyük = L, Yok = N, Kolye = P, Kılıf = S, Bölge = Z',\n",
        "    ('e', 'f', 'l', 'n', 'p'))\n",
        "  spore_print_color = st.selectbox(\n",
        "    'spor-baskı-renk: siyah = k, kahverengi = n, buff = b, çikolata = h, yeşil = r, turuncu = o, mor = u, beyaz = w, sarı = y',\n",
        "    ('k', 'n', 'b', 'h', 'r', 'o', 'u', 'w', 'y'))\n",
        "  population = st.selectbox(\n",
        "    'Nüfus: Bol=A,Kümeli=C,Sayılı=N,Dağınık=S,Birkaç=V,Yalnız=Y',\n",
        "    ('a', 'c', 'n', 's', 'v', 'y'))\n",
        "  habitat = st.selectbox(\n",
        "    'Habitat: otlar = g, yapraklar = l, çayırlar = m, yollar = p, kentsel = u, atık = w, ormanlar = d',\n",
        "    ('g', 'l', 'm', 'p', 'u', 'w', 'd'))\n",
        "\n",
        "  #Veriler string değerler olarak alındığı için encode edilmesi için dataframe oluşturulması.\n",
        "  user_input_mushroom = pd.DataFrame({\n",
        "    'cap-shape': [cap_shape],\n",
        "    'cap-surface': [cap_surface],\n",
        "    'cap-color': [cap_color],\n",
        "    'bruises': [bruises],\n",
        "    'odor': [odor],\n",
        "    'gill-attachment': [gill_attachment],\n",
        "    'gill-spacing': [gill_spacing],\n",
        "    'gill-size': [gill_size],\n",
        "    'gill-color': [gill_color],\n",
        "    'stalk-shape': [stalk_shape],\n",
        "    'stalk-root': [stalk_root],\n",
        "    'stalk-surface-above-ring': [stalk_surface_above_ring],\n",
        "    'stalk-surface-below-ring': [stalk_surface_below_ring],\n",
        "    'stalk-color-above-ring': [stalk_color_above_ring],\n",
        "    'stalk-color-below-ring': [stalk_color_below_ring],\n",
        "    'veil-type': [veil_type],\n",
        "    'veil-color': [veil_color],\n",
        "    'ring-number': [ring_number],\n",
        "    'ring-type': [ring_type],\n",
        "    'spore-print-color': [spore_print_color],\n",
        "    'population': [population],\n",
        "    'habitat': [habitat]\n",
        "    })\n",
        "\n",
        "  user_encoded = encoder_mushroom.transform(user_input_mushroom)\n",
        "\n",
        "  user_encoded_df = pd.DataFrame(user_encoded, columns=encoder_mushroom.get_feature_names_out(categorical_columns_mushroom))\n",
        "  tahminMushRoomRf=mushRoomRf.predict(user_encoded_df)\n",
        "  tahminMushRoomAb=mushRoomAb.predict(user_encoded_df)\n",
        "  tahminMushRoomBg=mushRoomBg.predict(user_encoded_df)\n",
        "  tahminMushRoomSg=mushRoomSg.predict(user_encoded_df)\n",
        "\n",
        "\n",
        "  if st.button(\"Mushroom Predict\"):\n",
        "    st.text(\"Random Forest\")\n",
        "    if tahminMushRoomRf[0]==\"e\":\n",
        "      st.success(\"Bu mantar yenilebilir. Afiyet Olsun\")\n",
        "    elif tahminMushRoomRf[0]==\"p\":\n",
        "      st.warning(\"Bu mantar zehirlidir. Eğer tükettiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "\n",
        "    st.text(\"Ada Boost\")\n",
        "    if tahminMushRoomAb==\"e\":\n",
        "      st.success(\"Bu mantar yenilebilir. Afiyet Olsun\")\n",
        "    elif tahminMushRoomAb==\"p\":\n",
        "      st.warning(\"Bu mantar zehirlidir. Eğer tükettiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "    st.text(\"Bagging\")\n",
        "    if tahminMushRoomBg==\"e\":\n",
        "      st.success(\"Bu mantar yenilebilir. Afiyet Olsun\")\n",
        "    elif tahminMushRoomBg==\"p\":\n",
        "      st.warning(\"Bu mantar zehirlidir. Eğer tükettiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "    st.text(\"Stacking\")\n",
        "    if tahminMushRoomSg==\"e\":\n",
        "      st.success(\"Bu mantar yenilebilir. Afiyet Olsun\")\n",
        "    elif tahminMushRoomSg==\"p\":\n",
        "      st.warning(\"Bu mantar zehirlidir. Eğer tükettiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0B1zEvtv_p1",
        "outputId": "093407cd-24df-48b7-fb62-09dfe309b6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile -a app.py\n",
        "# Su İçilebilirlik Modelinin Oluşturulması\n",
        "df_water=pd.read_csv(\"/content/water_potability.csv\")\n",
        "\n",
        "x_water=df_water.drop(\"Potability\",axis=1)\n",
        "y_water=df_water[\"Potability\"]\n",
        "#Verinin içinde eksik değerler olduğu için ortalama stratejisiyle eksik değerlerin doldurulması (imputer kütüphanesi)\n",
        "xwater_train,xwater_test,ywater_train,ywater_test=train_test_split(x_water,y_water,test_size=0.2)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "xwater_train = imputer.fit_transform(xwater_train)\n",
        "xwater_test = imputer.transform(xwater_test)\n",
        "\n",
        "#Random Forest modelinin oluşturulup eğitilmesi\n",
        "waterRf=RandomForestClassifier()\n",
        "waterRf.fit(xwater_train,ywater_train)\n",
        "\n",
        "# #Adaboost modelinin oluşturulup eğitilmesi\n",
        "waterAb=AdaBoostClassifier()\n",
        "waterAb.fit(xwater_train,ywater_train)\n",
        "\n",
        "# #BaggingClassifier modelinin oluşturulup eğitilmesi\n",
        "waterBg=BaggingClassifier()\n",
        "waterBg.fit(xwater_train,ywater_train)\n",
        "\n",
        "# #StackingClassifier modelinin oluşturulup eğitilmesi\n",
        "waterSg=StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
        "waterSg.fit(xwater_train,ywater_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r4aE8A_Liny",
        "outputId": "d3d441f9-f4a7-4ee8-9549-650436b8ad82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile -a app.py\n",
        "\n",
        "#Su İçilebilirlik Tahmin\n",
        "if rad==\"Su İçilebilirliği\":\n",
        "  st.header(\"Su İçilebilir Mi İçilemez Mi ?\")\n",
        "\n",
        "  # Kullanıcıdan tahmin için verilerin number imputla verilerin alınması\n",
        "  ph = st.number_input(\"ph (0.0-14.0) \", min_value=0.0, max_value=14.0)\n",
        "  hardness = st.number_input(\"Hardness (47.4-323.0)\", min_value=47.4, max_value=323.0)\n",
        "  solids = st.number_input(\"Solids (321.0-61000.2)\", min_value=321.0, max_value=61000.2)\n",
        "  chloramines = st.number_input(\"Chloramines (0.35-13.1)\", min_value=0.35, max_value=13.1)\n",
        "  sulfate = st.number_input(\"Sulfate (129.0-481.0)\", min_value=129.0, max_value=481.0)\n",
        "  conductivity = st.number_input(\"Conductivity (181.0-753.0)\", min_value=181.0, max_value=753.0)\n",
        "  organic_carbon = st.number_input(\"Organic_carbon (2.2-28.3)\", min_value=2.2, max_value=28.3)\n",
        "  trihalomethanes = st.number_input(\"Trihalomethanes (0.74-124.0)\", min_value=0.74, max_value=124.0)\n",
        "  turbidity = st.number_input(\"Turbidity (1.45-6.74)\", min_value=1.45, max_value=6.74)\n",
        "\n",
        "  #Kullanıcdan alınan verilerle modellerin eğitilmesi\n",
        "  waterRfTahmin=waterRf.predict([[ph,hardness,solids,chloramines,sulfate,conductivity,organic_carbon,trihalomethanes,turbidity]])[0]\n",
        "  waterAbTahmin=waterAb.predict([[ph,hardness,solids,chloramines,sulfate,conductivity,organic_carbon,trihalomethanes,turbidity]])[0]\n",
        "  waterBgTahmin=waterBg.predict([[ph,hardness,solids,chloramines,sulfate,conductivity,organic_carbon,trihalomethanes,turbidity]])[0]\n",
        "  waterSgTahmin=waterSg.predict([[ph,hardness,solids,chloramines,sulfate,conductivity,organic_carbon,trihalomethanes,turbidity]])[0]\n",
        "\n",
        "\n",
        "  if st.button(\"Water Predict\"):\n",
        "\n",
        "    st.text(\"Random Forest\")\n",
        "    if waterRfTahmin==1:\n",
        "      st.success(\"Bu su içilebilir. Afiyet olsun.\")\n",
        "    elif waterRfTahmin==0:\n",
        "      st.warning(\"Bu su içilemez. Lütfen içtiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "    st.text(\"Ada Boost\")\n",
        "    if waterAbTahmin==1:\n",
        "      st.success(\"Bu su içilebilir. Afiyet olsun.\")\n",
        "    elif waterAbTahmin==0:\n",
        "      st.warning(\"Bu su içilemez. Lütfen içtiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "    st.text(\"Bagging\")\n",
        "    if waterBgTahmin==1:\n",
        "      st.success(\"Bu su içilebilir. Afiyet olsun.\")\n",
        "    elif waterBgTahmin==0:\n",
        "      st.warning(\"Bu su içilemez. Lütfen içtiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "    st.text(\"Stacking\")\n",
        "    if waterSgTahmin==1:\n",
        "      st.success(\"Bu su içilebilir. Afiyet olsun.\")\n",
        "    elif waterSgTahmin==0:\n",
        "      st.warning(\"Bu su içilemez. Lütfen içtiyseniz en yakın sağlık kuruluşuna gidiniz.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhW3P6dBNIMm",
        "outputId": "9d9f3a09-4409-4780-9dbf-91052d9d138f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7HNMMuz-Sow",
        "outputId": "34b1785c-4db7-4823-9475-7da10cc055c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.173.2.102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71FZyVqX-VPS",
        "outputId": "57a81516-2e24-4489-ee96-80576065bc97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.173.2.102:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.894s\n",
            "your url is: https://clean-showers-cut.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hI5hrNlqAJRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}